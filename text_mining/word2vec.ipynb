{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## simple train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.word2vec import Word2Vec\n",
    "import numpy\n",
    "import jieba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read document\n",
    "data = []\n",
    "for i in range(1, 4):\n",
    "    with open('word2vec_example_data/DATA/{}.txt'.format(i), 'r') as r:\n",
    "        data.append(r.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\CM\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 1.722 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "# cut word for each document\n",
    "corpus = [jieba.lcut(d) for d in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modeling\n",
    "test_model = Word2Vec(corpus)\n",
    "# model.save('test_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['到', '「', '相關', '不', '代表', '因果', '」', '，', '但', '如何', '關', '係', '？', '\\n', ' ', '你', '我們', '的', '！', '讓', '是', '生物', '學及', '醫學', '中', '很多', '不是', 'X', 'Y', '機會', '一定', '會', '引起', '。', '9', '分析', '一個', '科學', '這個', '都', '可以', '說', '後', '又', '他們', '覺得', '了', '、', '政府', '數據', '我', '對', '所以', '其實', '知識', '方法', '比', '重要', '因為', '在', '之前', '有', '他', '使用', '而', '也', '於', '為', 'micafungin', '去', '病人', '很', '尿', '減少', '要', '出', '用', '相同', '不同', '干擾', '因子', '（', '）', '越', '高', '溺水', '人數', '多', '它們', '上', '人', '疫苗', '美國', '開始', 'MMR', '自閉', '症', '上升', '與', '發生', '香港', ')', '導致', '.', '被', '’', '如果', '希爾', '準則', '就', '大家', '即', '個', '最', '已經', '1', '似乎', '-', '更', 'Google', '高材生', '公司', '：', 'a', 'and', 'degrees', 'to', 'ability', ',', '“', 'the', 'people', '”', 'not', 'in', 'that', 'Bock', 'is', '從', '什麼', '發展', '把', '開放', '改變', '開放銀行', 'Open', '金融', '澳洲', '台灣', '銀行', '客戶', '資料', '消費者', 'API', '業者', 'FinTech'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model.wv.vocab.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00407202, -0.02117454, -0.00826798, -0.0034188 , -0.01232004,\n",
       "        0.00529503, -0.00470355,  0.01519602, -0.00578362, -0.01810468,\n",
       "        0.01888492, -0.02731648, -0.00050291, -0.02759987,  0.02738652,\n",
       "        0.03437208,  0.03763647, -0.01350995, -0.00555092, -0.03936609,\n",
       "       -0.00181554,  0.01942213,  0.02434385,  0.00595702,  0.00353702,\n",
       "        0.01977598, -0.02821808, -0.00893409, -0.00147275, -0.02003877,\n",
       "        0.00293566, -0.00672593, -0.00949511, -0.02257096, -0.01942433,\n",
       "        0.01474952,  0.00074135, -0.0177024 ,  0.02611127, -0.01583422,\n",
       "       -0.0028158 , -0.0109705 , -0.00100238, -0.04397964, -0.02132553,\n",
       "        0.01559202,  0.01665685,  0.02322528, -0.02034222, -0.0490157 ,\n",
       "        0.02435304,  0.01046734,  0.013324  , -0.00415654,  0.00807828,\n",
       "        0.02394705, -0.00697511, -0.05519076,  0.00208933, -0.03818194,\n",
       "       -0.02503202, -0.0138779 ,  0.02209434, -0.02258686, -0.00609538,\n",
       "       -0.00577252, -0.02601128, -0.04196115,  0.01082058, -0.00200201,\n",
       "       -0.01843272,  0.04985778, -0.04643721,  0.00659497,  0.00317855,\n",
       "       -0.06538814,  0.00318489,  0.02544248,  0.02646422, -0.02925857,\n",
       "       -0.00204491, -0.04337093, -0.02799284, -0.00375705,  0.00295354,\n",
       "        0.00753388,  0.02290357, -0.00783857,  0.00440599,  0.01661836,\n",
       "        0.0243722 , -0.02004037, -0.00104538, -0.00533322, -0.03038799,\n",
       "       -0.04239002,  0.00537488,  0.00185917, -0.00647984, -0.01460015],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model.wv['醫學']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17278327"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy.linalg.norm(test_model.wv['醫學'] - test_model.wv['銀行'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\CM\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `similarity` (Method will be removed in 4.0.0, use self.wv.similarity() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.98542416"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model.similarity('醫學', '銀行')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Harry Potter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import numpy\n",
    "from stop_words import get_stop_words\n",
    "import re\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"word2vec_example_data/harrypotter.txt\", 'r') as r:\n",
    "    harry = r.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-07-18 12:19:26,222 : INFO : loading Word2Vec object from word2vec_example_data/model\n",
      "2019-07-18 12:19:26,226 : WARNING : this function is deprecated, use smart_open.open instead\n",
      "2019-07-18 12:19:26,639 : INFO : loading wv recursively from word2vec_example_data/model.wv.* with mmap=None\n",
      "2019-07-18 12:19:26,639 : INFO : setting ignored attribute cum_table to None\n",
      "2019-07-18 12:19:26,639 : INFO : Model saved using code from earlier Gensim Version. Re-loading old model in a compatible way.\n",
      "2019-07-18 12:19:26,639 : INFO : loading Word2Vec object from word2vec_example_data/model\n",
      "2019-07-18 12:19:26,649 : WARNING : this function is deprecated, use smart_open.open instead\n",
      "2019-07-18 12:19:27,110 : INFO : loading wv recursively from word2vec_example_data/model.wv.* with mmap=None\n",
      "2019-07-18 12:19:27,110 : INFO : setting ignored attribute cum_table to None\n",
      "2019-07-18 12:19:27,110 : INFO : setting ignored attribute syn0norm to None\n",
      "2019-07-18 12:19:27,110 : INFO : loaded word2vec_example_data/model\n"
     ]
    }
   ],
   "source": [
    "# load harry potetr model\n",
    "model = Word2Vec.load('word2vec_example_data/model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = get_stop_words('en')\n",
    "\n",
    "h_mix = {\n",
    "        'g': ['brave', 'courageous', 'daring','clever','intelligent','fire','lion','red','gold','reckless','bravery', 'chivalry', 'courage','cleverness','leadership','hero','heroic','adventurous'],\n",
    "        's': ['cunning', 'ambitious', 'determined', 'clever','snake','water','antagonist','green','silver','ambition', 'determination', 'cleverness'],\n",
    "        'h': ['dedicated', 'patient', 'tolerant', 'loyal','humble','friendly','decent','earth','badger','yellow','black','dedication', 'patience', 'kindness', 'tolerance', 'loyalty'],\n",
    "        'r': ['intelligent' ,'wise' ,'creative', 'original', 'individual','arrogant','eagle','air','blue','brown','bronze','black','intelligence', 'wit', 'wisdom', 'creativity']\n",
    "}\n",
    "h = h_mix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove stop word, punctuation, and transform to lowercase\n",
    "def text_pre_process(text):\n",
    "    stop_words = get_stop_words('en')\n",
    "    words = re.sub(r'[^\\w]', ' ', str(text)).lower().split()\n",
    "    valid_words = [word for word in words if word not in stop_words]\n",
    "    return valid_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define distance\n",
    "def dist1(word, house):\n",
    "    mean = 0.0\n",
    "    n = 0\n",
    "    for attr in h[house]:\n",
    "        mean += numpy.linalg.norm(model.wv[attr] - model.wv[word])\n",
    "        n = n+1 #忘記這個 n 要幹嘛了\n",
    "    mean /= len(h[house])\n",
    "    return mean\n",
    "\n",
    "def dist2(word,house):\n",
    "    try:\n",
    "            tmp = model.wv[word]\n",
    "    except:\n",
    "        # print(word)\n",
    "        return 1000\n",
    "    return min( [numpy.linalg.norm(model.wv[attr] - tmp) for attr in h[house]] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distance 1\n",
      "g 5.775136762195164\n",
      "s 6.938896814982097\n",
      "h 6.272163406014442\n",
      "r 8.674353390932083\n",
      "\n",
      "distance 2\n",
      "g 3.0798986\n",
      "s 3.404738\n",
      "h 3.009806\n",
      "r 3.189788\n"
     ]
    }
   ],
   "source": [
    "word = \"kindly\"\n",
    "# word = \"brave\"\n",
    "\n",
    "\n",
    "print(\"distance 1\")\n",
    "for house in h:\n",
    "    print(house, dist1(word, house))\n",
    "    \n",
    "print(\"\\ndistance 2\")\n",
    "for house in h:\n",
    "    print(house, dist2(word, house))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Algorithm 1 total and mean\n",
    "def A1(words):\n",
    "    # print('Algorithm1')\n",
    "    total = { 'g': 0.0, 's': 0.0, 'h': 0.0, 'r': 0.0 }\n",
    "    for word in words:\n",
    "        try:\n",
    "            for house in h:\n",
    "                total[house] += dist1(word, house)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    result1 = 'g'\n",
    "    for house in total:\n",
    "        if total[house] < total[result1]:\n",
    "            result1 = house\n",
    "    # print()\n",
    "    # print(total)\n",
    "    # print('result1:', result1)\n",
    "    return result1\n",
    "\n",
    "# Algorithm 2 \n",
    "def A2(words):\n",
    "    Min_thr=10\n",
    "    # print('Algorithm2')\n",
    "    valid_words = { 'g': [], 's': [], 'h': [], 'r': [] }\n",
    "    score = { 'g': 0, 's': 0, 'h': 0, 'r': 0 }\n",
    "    for word in words:\n",
    "        try:\n",
    "            if word == 'harry':\n",
    "                continue\n",
    "            flag = False\n",
    "            for house in h:\n",
    "                if flag == False:\n",
    "                    flag = True\n",
    "                    min_house = house\n",
    "                    min_dist = dist1(word, house)\n",
    "                else:\n",
    "                    tmp_dist = dist1(word, house)\n",
    "                    if tmp_dist < min_dist:\n",
    "                        min_house = house\n",
    "                        min_dist = tmp_dist\n",
    "            if min_dist < 5:\n",
    "                score[min_house] += 1\n",
    "                valid_words[min_house].append((word, min_dist))\n",
    "        except:\n",
    "            continue\n",
    "    # print('validwords',valid_words)\n",
    "\n",
    "    result2=judge(score,2)\n",
    "    # print()\n",
    "    # print(score)\n",
    "    # print('result2:', result2)\n",
    "    # print('Min_thr:',Min_thr)\n",
    "    return result2\n",
    "    \n",
    "#Algorithm3\n",
    "def A3(words):\n",
    "    nstdthr = 0.17\n",
    "    # print('Algorithm3')\n",
    "    distance = { 'g': 0, 's': 0, 'h': 0, 'r': 0 }\n",
    "    for word in words:\n",
    "        try:\n",
    "            tmpd=[]\n",
    "            tmpdis={ 'g': 0, 's': 0, 'h': 0, 'r': 0 }\n",
    "            mean=0\n",
    "            for house in h:\n",
    "                minn = dist2(word,house)\n",
    "                tmpd.append(minn)\n",
    "                # print(word,house,minn)\n",
    "                tmpdis[house]=minn\n",
    "                mean+=minn\n",
    "            mean/=4\n",
    "            nstd=numpy.std(tmpd)\n",
    "            if mean<7 and nstd >nstdthr:\n",
    "                # print(word,':::')\n",
    "                # print(tmpdis)\n",
    "                # print(nstd,'aaaaa')\n",
    "                for house in h:\n",
    "                    distance[house]+=tmpdis[house]\n",
    "        except:\n",
    "            print('uhhh in A3:',word)\n",
    "    result3=judge(distance,3)\n",
    "    return result3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def judge(distance, mode):\n",
    "    result = 'g'\n",
    "    summ = sum(distance.values())\n",
    "    if mode==3:\n",
    "        min(distance, key=distance.get)\n",
    "    elif mode==2:\n",
    "        for house in points:\n",
    "            if points[house] > points[result]:\n",
    "                result = house\n",
    "                resultnum=points[house]\n",
    "                \n",
    "    if summ==0:\n",
    "        return 'jerr'#judge err\n",
    "    else:\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text2house(text):\n",
    "    if text=='':\n",
    "        return 'e' #empty\n",
    "    valid_words=text_pre_process(text)\n",
    "    house=A3(valid_words)\n",
    "    if house=='jerr':\n",
    "        print('your house is remained undecided, maybe your age is under 30')\n",
    "        return house\n",
    "    else:\n",
    "        houses = {\n",
    "                'g': 'gryffindor',\n",
    "                'h': 'hufflepuff',\n",
    "                'r': 'ravenclaw',\n",
    "                's': 'slytherin'\n",
    "            }\n",
    "        return houses[house]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gryffindor'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text2house(harry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-07-18 12:19:55,495 : INFO : precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('slytherin', 0.5084857940673828)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive=['malfoy', 'gryffindor'], negative=['harry'], topn=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
